# Assignment 1

## 学生信息
- 姓名：陈嘉雷
- 学号：2200011418

## 0. 文件说明
- `llm.py`为最终程序
- `.env`用于存放各种API Key
- 其余文件为课程网站或者llm聚合平台下载的api调用示例


## 1. 概述
这是一个基于 Python 的 LLM 多轮对话程序，通过调用阿里云百炼平台的API实现与大语言模型的交互。主要功能如下：
- 多模型支持：可在在 qwen-plus, deepseek-v3.1, Moonshot-Kimi-K2-Instruct, glm-4.5 等多个预设模型间切换。
- 智能对话记忆：自动管理对话历史，仅保留最近的 N 轮对话（可配置），防止超出模型上下文长度限制。
- Token 限制：在发送请求前估算并限制总 Token 数量，确保 API 调用成功率，并节约成本。
- 流式输出：实时显示模型的响应内容，提供更流畅的交互体验。
- 用量统计：每次对话结束后，清晰地展示输入、输出及总计的 Token 使用量。
- 自动重试：当遇到 API 请求速率限制 (RateLimitError) 时，程序会采用指数退避策略自动重试，增强稳定性。
- 环境变量配置：通过 .env 文件安全地管理 API Key，避免硬编码泄露风险。

## 2. 使用方法
从文件夹`~/Assignments/Assignment1`启动程序后，你将看到如下界面：

**1. 选择模型：**

程序启动时，会列出可用的模型。输入模型前面的数字编号，然后按 Enter。如果直接按 Enter，将默认选择第一个模型 (qwen-plus)。
```bash
请选择模型：
1. qwen-plus
2. deepseek-v3.1
3. Moonshot-Kimi-K2-Instruct
4. glm-4.5
输入模型编号（默认1）: 
```

**2. 开始对话：**

选择模型后，您就可以在`你: `提示符后输入问题或对话内容，然后按 Enter。

**3. 接收回复:**

模型会以流式的方式逐步输出回复。回复结束后，会显示本次请求的 Token 用量统计。

**4. 退出程序：**

在任何时候，当您想结束对话时，只需输入 exit (不区分大小写) 并按 Enter。
```bash
你: exit
已退出对话。
```

## 3. 故障排查：

**1. `ValueError: 请设置环境变量 DASHSCOPE_API_KEY`**
- 状况：运行脚本后，程序立即报错退出，并显示上述信息。
- 原因：程序没有成功加载到你的APIKey。 
- 解决方法：确保程序是从作业1项目的主目录`~/Assignments/Assignment1`文件夹开始运行的。

**2. `请求失败: RateLimitError... 秒后重试...`**
- 状况：对话过程中，程序暂停并显示此信息。
- 原因：这是正常现象。你向模型发送请求的频率过快，触发了 API 的速率限制。
- 解决方法：无需任何操作。本程序的智能重试机制已自动激活。它会等待一小段时间后自动重新发送请求。如果持续出现，请放慢提问速度。

**3. 其他**
- 我也不知道

